{"root":
  {
    "title": "Fantastic Expressions and Where to Find Them: Chinese Simile Generation with Multiple Constraints",
    "author": ["Kexin Yang", "Dayiheng Liu", "Wenqiang Lei", "Baosong Yang", "Xiangpeng Wei", "Zhengyuan Liu", "Jun Xie"],
    "abstract": "Similes occur in the creative context of describing a concept (i.e., tenor) by making a literally false yet figuratively meaningful comparison to another (i.e., vehicle). Previous efforts form simile generation as a context-free generation task, focusing on simile-style transfer or writing a simile from a given prefix. However, generated texts under such settings might be undesirable, such as hardly meeting the simile definition (e.g., missing vehicle) or difficult to address certain preferences of content as humans wish (e.g., describe the color of apples through the simile). We believe that a simile could be more qualified and user-oriented if incorporated with pre-specified constraints. To this end, we introduce controllable simile generation (CSG), a new task that requires the model to generate a simile with multiple simile elements, e.g., context and vehicle. To facilitate this task, we present GraCe, including 61.3k simile-element annotated Chinese similes. Based on it, we propose a CSG model Similor to benchmark this task, including a vehicle retrieval module Scorer to obtain the explicable comparison for a given tenor in the vehicle-unknown situation. Both statistical and experimental analyses show that GraCe is of high quality beyond all other Chinese simile datasets, in terms of the number (8 vs. 3) of annotation elements, Is-Simile accuracy (98.9% vs. 78.7%), and increasing model-performance gains for both uncontrollable and controllable simile generation. Meanwhile, Similor can serve as a strong baseline for CSG, especially with Scorer, which beats model-based retrieval methods without any re-training.",
    "introduction": "Similes are widely used and stimulate people's creativity (Li et al., 2022). According to Rhetoric's classical terms (Campbell, 1988), a simile uses comparison words (i.e., comparator) to make a literally false comparison between a concept (i.e., tenor) and another (i.e., vehicle). It also ensures this comparison pair is figuratively meaningful by examining whether they have shared properties (i.e., ground) (Tartakovsky et al., 2019). Notably, ground can be expressed in an explicit or implicit way (Chakrabarty et al., 2020). As shown in Figure 1 qualified samples. \"Maple leaves are like torches of fired red.\" has the explicit ground that the tenor \"maple leaves\" and the vehicle \"torches\" have the similar color of \"fired red\", while \"maple leaves are like small palms.\" implies the ground that they have a similar pentagram shape.\n\nAlthough simile detection has been widely explored (Liu et al., 2018; Zeng et al., 2020; Mao and Li, 2021), simile generation is still in its fledgling stage. Existing efforts focus on context-free simile generation, including: 1) style-transfer-based and 2) prefix-based simile generation. The former paraphrases a literal sentence into its simile version (Chakrabarty et al., 2020; Zhang et al., 2021) and the latter aims at writing a simile from a pre-specified tenor (Li et al., 2022; Chen et al., 2022). Despite great progress, such experiment settings may result in undesirable results, such as unqualified similes or being unable to meet the content preferences of humans wish. As shown in Figure 1, the former means the generated sentences may miss indispensable simile elements or generate incoherence elements, i.e., generating element-incomplete or -mismatched samples. For example, \"maple leaves are small and beautiful.\" misses both tenor and vehicle and \"maple leaves are like small green fans.\" has inconsistent vehicle \"green fans\" with the context \"mountains are red\". The second problem may arise when users wish to describe the color of maple leaves by similes but get \"maple leaves are like small palms.\", although it is qualified according to the simile definition.\n\nTo solve these problems, we explore incorporating various constraints into simile generation. Specifically, we introduce a new task of controllable simile generation (CSG) – generating a simile with multiple simile elements (e.g., vehicle, context, etc.) from a given prefix (i.e., topic). We collect a Fine-Grained annotated Chinese Simile dataset (GraCe), containing annotated 61.3k similes from 260k cleaned text of student compositions. As shown in Table 1, we expand three commonly annotated elements (i.e., tenor, vehicle and comparator) (Li et al., 2022) to eight, such as the context element that could put each simile into a more naturally-using situation (Sun et al., 2022). In details, we annotate explicit ground to better understand the simile comparison. As for implicit ground, we try to interpret the relationship between tenor and vehicle by their cognitive properties. Such property is a set of adjectives that describe the distinctive features of the corresponding nouns (Veale and Hao, 2007), which helps to understand the comparison from the aspect of Cognitive Linguistics (Kövecses, 2010). To benchmark CSG, we build the model Similor, which first retrieves vehicle (if it is unknown) by the module Scorer (a Shared cognitive-property-based retrieval method) for the given tenor, then incorporates all constraints and the input prefix (i.e., topic) to generate the simile. Both statistical and experimental analyses show that GraCe is of high quality beyond previous Chinese simile datasets. Meanwhile, Similor can successfully incorporate the constraints in the outputs. Especially in the vehicle-unknown setup, Scorer beats the model-based retrieval method both in automatic and human evaluations without any re-training.",
    "relatedwork": "Different from metaphor (Yu and Wan, 2019; Chakrabarty et al., 2021a; Stowe et al., 2021) that using implicit comparators, similes are much easier to be located. However, existing efforts mainly focus on simile detection (Liu et al., 2018; Zeng et al., 2020; Mao and Li, 2021), leaving simile generation under-explored. Previous work on context-free simile generation can be divided into: 1) style-transfer-based and 2) prefix-based simile generation. The first forms this task as paraphrasing a literal sentence into a simile-style sentence, and automatically edits self-labeled similes to their literal version for building pairs of (literal sentence, simile). For example, SCOPE (Chakrabarty et al., 2020) uses commonsense properties words (Bosselut et al., 2019) of the vehicle to replace it in a simile, then removes the comparator to form the final literal sentence. WPS (Zhang et al., 2021) deletes a span from a simile to obtain the literal sentence. The second focuses on generating the comparator and tenor from a pre-specified tenor. Liu et al. (2019b) uses a continuous latent variable as a rhetoric controller to generate Chinese poetry. CMC (Li et al., 2022) provides a multi-task framework that leverages unlabeled data to enhance performance. Chen et al. (2022) use three words triple (tenor, attribute, vehicle) and a relationship pattern to hint the model for generating simile. Different from all of them, we focus on controllable simile generation – generating a simile with multiple constraints. To make it a computationally feasible task, we build a high-quality dataset GraCe and a CSG model Similor with Scorer to ensure explicable tenor-vehicle pairs in generated similes. As shown in Table 1, GraCe is far beyond the most recent dataset CMC (Li et al., 2022) in terms of collected samples (61.3k v.s. 2.7k), simile quality (98.9% v.s. 78.7% Is-Simile accuracy) and the number of annotated elements (eight v.s. three)."},
  "leaves":
   [
     {
       "title": "How to Avoid Sentences Spelling Boring? Towards a Neural Approach to Unsupervised Metaphor Generation",
       "author": ["Zhiwei Yu", "Xiaojun Wan"],
       "year": 2019,
       "abstract": "Metaphor generation attempts to replicate human creativity with language, which is an attractive but challengeable text generation task. Previous efforts mainly focus on template-based or rule-based methods and result in a lack of linguistic subtlety. In order to create novel metaphors, we propose a neural approach to metaphor generation and explore the shared inferential structure of a metaphorical usage and a literal usage of a verb. Our approach does not require any manually annotated metaphors for training. We extract the metaphorically used verbs with their metaphorical senses in an unsupervised way and train a neural language model from wiki corpus. Then we generate metaphors conveying the assigned metaphorical senses with an improved decoding algorithm. Automatic metrics and human evaluations demonstrate that our approach can generate metaphors with good readability and creativity.",
       "introduction": "Metaphor is a kind of language filled with vitality and elasticity. It employs words in a way that deviates from their normal meaning to represent another concept (Li and Sporleder, 2010). Using metaphor allows us to express not just information but also real feelings and complex attitudes. There is a clear need in computational metaphor generation whose insightful results can be used in many applications from entertainment to education (Veale, 2016). Besides, a unified metaphor annotation procedure and creation of a large publicly available metaphor corpus are in great demands. Such resources make it possible to interpretate the identified metaphorical expressions and enhance the performance on other Natural Language Processing (NLP) applications (Shutova, 2010).\n\nAlthough metaphor has a long history of academic studies in both philosophy and linguistics (Genesereth, 1980; G. and M., 1985), it still remains a tough problem for the NLP community. As the metaphor is hardly to be well-defined and modeled, little work focuses on the metaphor generation. Most of the previous efforts rely on hand-coded knowledge (Martin, 1990; Feldman and Narayanan, 2004; Agerri et al., 2007), which heavily constrains the diversity of generated metaphors.\n\nThe end-to-end approach presented to sequence learning has been proved effective on the generation tasks like machine translation (Sutskever et al., 2014), abstractive summarization (Tan et al., 2017), product review generation (Zang and Wan, 2017) and multi-label classification (Yang et al., 2018). The approach is able to train a language model which can generate fluent and creative sentences with sufficient corpus. Unfortunately, in spite of the industrious exploration of the metaphor corpus, the annotated data available now is still far from training a good language model. To the best of our knowledge, there has been no work combining metaphor generation with the end-to-end approach.\n\nIn this paper, we propose a neural approach for metaphor generation trained with Wiki corpus rather than the limited annotated metaphor corpus, which assures the quality of the language model. The approach is shown in Figure 1. Relevant statistics demonstrate that the most frequent type of metaphor is expressed by a verb (Martin, 2006; Steen, 2010). In this paper, we focus on generating verb-oriented metaphors. We use an unsupervised method to extract the metaphorically used verbs in Wiki corpus. A metaphorical pair consists of a target verb (e.g. “devoured”) and a fit word (e.g. “enjoyed”). And it is used to model the metaphorical usage of the target verb. According to Narayanan (1997), a metaphorical usage and a literal usage share inferential structure. We follow this intuition to find an intersection between the metaphorical usage and the literal usage of a word. For example, in “she devoured (enjoyed) his novels”, the literal sense of “enjoyed” represents the contextual sense of “devoured” in such contexts. But the similarity between “enjoyed” and “devoured” is low, which means the target verb “devoured” is merely used in such sense and can be seen as a metaphorically used verb.\n\nFor metaphor generation, we first propose a POS constrained language model to generate a sentence containing a given verb and use an elaborately designed algorithm to consider its fit word simultaneously while decoding. For a profound exploration, we introduce automatic metrics as well as manual ways to evaluate the generation results. Experimental results demonstrate that our approach is capable of generating fluent and seemly metaphors. All the generated metaphors are novel and do not exist in the corpus.\n\nTo summarise, the contributions of our work are as follows:\n• As far as we know, our work is the first endeavor to adopt the end-to-end framework on metaphor generation. Besides, the proposed method does not require any manually labeled metaphor corpus.\n• We automatically extract the verbs and their fit words in the corpus in an unsupervised way and use them (e.g. “devoured”, “enjoyed”) to model the metaphorical senses of the verbs for the generation process. We further explore the semantic shift of a verb by changing the adjustable factors.\n• Both automatic metrics and human evaluation results demonstrate the efficacy of our model. Our model outperforms the baseline models on 3 aspects significantly.",
       "charge":  false
     },
     {
       "title": "MERMAID: Metaphor Generation with Symbolism and Discriminative Decoding",
       "author":["Tuhin Chakrabarty", "Xurui Zhang", "Smaranda Muresan", "Nanyun Peng"] ,
       "year": 2021,
       "abstract": "Generating metaphors is a challenging task as it requires a proper understanding of abstract concepts, making connections between unrelated concepts, and deviating from the literal meaning. In this paper, we aim to generate a metaphoric sentence given a literal expression by replacing relevant verbs. Based on a theoretically-grounded connection between metaphors and symbols, we propose a method to automatically construct a parallel corpus by transforming a large number of metaphorical sentences from the Gutenberg Poetry corpus (CITATION) to their literal counterpart using recent advances in masked language modeling coupled with commonsense inference. For the generation task, we incorporate a metaphor discriminator to guide the decoding of a sequence to sequence model fine-tuned on our parallel data to generate high-quality metaphors. Human evaluation on an independent test set of literal statements shows that our best model generates metaphors better than three well-crafted baselines 66% of the time on average. A task-based evaluation shows that human-written poems enhanced with metaphors proposed by our model are preferred 68% of the time compared to poems without metaphors.",
       "introduction": "Czech novelist Milan Kundera in his book “The unbearable lightness of being\" said “Metaphors are not to be trifled with. A single metaphor can give birth to love.\" Metaphors allow us to communicate not just information, but also feelings and complex attitudes (Veale et al., 2016). While most computational work has focused on metaphor detection (Gao et al., 2018; Stowe et al., 2019; Shutova et al., 2010; Tsvetkov et al., 2014; Veale et al., 2016; Stowe and Palmer, 2018), research on metaphor generation is under-explored (Yu and Wan, 2019; Stowe et al., 2020). Generating metaphors could impact many downstream applications such as creative writing assistance, literary or poetic content creation.\n\nRelevant statistics demonstrate that the most frequent type of metaphor is expressed by verbs (Steen, 2010; Martin, 2006). We therefore focus on the task of generating a metaphor starting from a literal utterance (Stowe et al., 2020), where we transform a literal verb to a metaphorical verb. Table 1 shows examples of literal sentences and the generated metaphors.\n\nTo tackle the metaphor generation problem we need to address three challenges: 1) the lack of training data that consists of pairs of literal utterances and their equivalent metaphorical version in order to train a supervised model; 2) ensuring that amongst the seemingly endless variety of metaphoric expressions the generated metaphor can fairly consistently capture the same general meaning as the literal one, with a wide variety of lexical variation; and 3) computationally overcome the innate tendency of generative language models to produce literal text over metaphorical one.\n\nIn an attempt to address all these challenges, we introduce our approach for metaphor generation called MERMAID (MEtaphor geneRation with syMbolism And dIscriminative Decoding), making the following contributions:\n\n• A method to automatically construct a corpus that contains 93,498 parallel [literal sentence, metaphorical sentence] pairs by leveraging the theoretically-grounded relation between metaphor and symbols. Barsalou et al. (1999) showed how perceptual symbols arising from perception are used in conceptual tasks such as representing propositions and abstract concepts. Philosopher Susanne Langer in her essay “Expressiveness and Symbolism” stated “A metaphor is not language, it is an idea expressed by language, an idea that in its turn functions as a symbol to express something”. Our approach has two steps: 1) identify a set of sentences that contains metaphorical verbs from an online poetry corpus; 2) convert these metaphorical sentences to their literal versions using Masked Language Models and structured common sense knowledge achieved from COMET (Bosselut et al., 2019), a language model fine-tuned on ConceptNet (Speer et al., 2017). For the later, we exploit the SymbolOf relation to make sure the generated sentence that contains the literal sense of the verb has the same symbol as the metaphorical sentence. For example, for the metaphorical sentence “The turbulent feelings that surged through his soul\" our method will generate \"The turbulent feelings that continued through his soul\" maintaining the common symbolic meaning of (love, loss, despair, sorrow, loneliness) between the two (Section 2).\n\n• A metaphor discriminator that guides the decoding of a sequence-to-sequence model fine-tuned on our parallel data to generate high quality metaphors. Our system MERMAID, fine-tunes BART (Lewis et al., 2019) – a state of the art pre-trained denoising autoencoder built with a sequence to sequence model, on our automatically collected parallel corpus of [literal sentence, metaphorical sentence] pairs (Sec. 3.1) to generate metaphors. A discriminative model trained in identifying metaphors is further used to complement our generator and guide the decoding process to improve the generated output (Sec. 3.2). Human evaluations show that this approach generates metaphors that are better than two literary experts 21% of the time on average, better 81% of the time than two well-crafted baselines, and better 36% of the time than fine-tuned BART (Lewis et al., 2019) (Section 5).\n\n• A task-based evaluation to improve the quality of human written poems using metaphorical rewriting. Evaluation via Amazon Mechanical Turk shows that poems enhanced with metaphors generated by MERMAID are preferred by Turkers 68% of the times compared to poems without metaphors, which are preferred 32% of the times (Section 6).",
       "charge": false
     },
     {
       "title": "Metaphor Generation with Conceptual Mappings",
       "author":["Kevin Stowe", "Tuhin Chakrabarty", "Nanyun Peng", "Smaranda Muresan", "Iryna Gurevych"] ,
       "year": 2021,
       "abstract": "Generating metaphors is a difficult task as it requires understanding nuanced relationships between abstract concepts. In this paper, we aim to generate a metaphoric sentence given a literal expression by replacing relevant verbs. Guided by conceptual metaphor theory, we propose to control the generation process by encoding conceptual mappings between cognitive domains to generate meaningful metaphoric expressions. To achieve this, we develop two methods: 1) using FrameNet-based embeddings to learn mappings between domains and applying them at the lexical level (CM-Lex), and 2) deriving source/target pairs to train a controlled seq-to-seq generation model (CM-BART). We assess our methods through automatic and human evaluation for basic metaphoricity and conceptual metaphor presence. We show that the unsupervised CM-Lex model is competitive with recent deep learning metaphor generation systems, and CM-BART outperforms all other models both in automatic and human evaluations.",
       "introduction": "Recent neural models have led to important progress in natural language generation (NLG) tasks. While pre-trained models have facilitated advances in many areas of generation, the field of metaphor generation remains relatively unexplored. Moreover, the few existing deep learning models for metaphor generation (Yu and Wan, 2019; Stowe et al., 2020; Chakrabarty et al., 2020) lack any conceptualization of the meaning of the metaphors.\n\nThis work proposes the first step towards metaphor generation informed by the conceptual metaphor theory (CMT) (Lakoff and Johnson, 1980; Lakoff, 1993; Reddy, 1979). CMT holds that we use conceptual mappings between domains (conceptual structures that group related concepts) to generate linguistic metaphors. Metaphoric mappings consist of a source and a target conceptual domain. The source domain is the conceptual domain from which we draw the metaphorical expressions, while the target domain is the conceptual domain that we try to understand. A classical mapping is ARGUMENT IS WAR, in which we conceptualize the target argumentation domain as the more concrete source domain of war:\n\nThey fought against the contract.\nThey defended their new proposal.\nWe focus on verbs, as they are often the key component of metaphoric expressions (Steen et al., 2010; Martin, 2006). When used metaphorically, verbs typically evoke source domains (e.g. fought, defended in the above examples): they are concrete and are used to understand more abstract targets (i.e., argumentation verbs such as argued, supported) via conceptual mappings (Sullivan, 2013).\n\nWe propose a novel framework for metaphor generation informed by conceptual metaphor theory. Given a literal input sentence that evokes a target domain, we generate metaphoric sentences that evoke desired corresponding source domain(s). For example, given the literal sentence \"The party ended as soon as she left\" evoking the target domain CAUSE TO END, we can apply a variety of conceptual mappings to generate different metaphoric outputs evoking different source domains (see Figure 1). This allows us to generate metaphoric expressions that match known metaphoric mappings, as well as generating from unseen mappings to explore novel metaphors.\n\nOur contributions are:\n\nTwo metaphor generation models grounded in CMT: 1) An unsupervised lexical model relying on frame embeddings learned from Framenet (CM-Lex, Section 3.1) and 2) a BART (Lewis et al., 2020) model encoding source/target domain information through fine-tuning (CM-BART, Section 3.2).\nTwo metaphor generation tasks: 1) generate metaphoric expressions from known concept mappings, for which we provide gold standard test data, and 2) generate novel expressions from unknown metaphors using rare and unseen mappings (Section 4).\nA thorough evaluation using both automatic and human evaluations (Section 5). We show that our CM-BART model improves over all others in terms of metaphoricity (by ≥ 7%) and domain evocation (by ≥ 33%), and CM-Lex is competitive with previous neural models on metaphoricity while outperforming them on domain evocation (by ≥ 13%).",
       "charge": false
     },
     {
       "title": "Neural Multitask Learning for Simile Recognition",
       "author":["Lizhen Liu", "Xiao Hu", "Wei Song", "Ruiji Fu", "Ting Liu", "Guoping Hu"] ,
       "year": 2018,
       "abstract": "Simile is a special type of metaphor, where comparators such as like and as are used to compare two objects. Simile recognition is to recognize simile sentences and extract simile components, i.e., the tenor and the vehicle. This paper presents a study of simile recognition in Chinese. We construct an annotated corpus for this research, which consists of 11.3k sentences that contain a comparator. We propose a neural network framework for jointly optimizing three tasks: simile sentence classification, simile component extraction and language modeling. The experimental results show that the neural network based approaches can outperform all rule-based and feature-based baselines. Both simile sentence classification and simile component extraction can benefit from multitask learning. The former can be solved very well, while the latter is more difficult.",
       "introduction": "A metaphor is a figure of speech that describes an object or action in a way that isn’t literally true. Metaphors are common in human language. Shutova and Teufel (2010) reported that 241 among 760 sentences in an annotated corpus contain a metaphor. The use of metaphors helps to explain an idea or realize rhetorical effects through an analogical procedure. Metaphor analysis has been drawn more attention for expanding current natural language processing (NLP) to high-level semantic tasks (Carbonell, 1980).\n\nMetaphors reflect creative thought of humans. On the other hand, inferring the meaning of a metaphor has to integrate background knowledge, which makes it difficult to automatically recognize metaphors in language. Previous work on metaphor recognition mainly depends on linguistic cues (Goatly, 2011) and selectional preference violation on a pair of concepts (Fass, 1991) or their domains (Mason, 2004). The domains can be created by knowledge bases such as WordNet (Mason, 2004) or based on automatic clustering (Shutova et al., 2010).\n\nIn this paper, we focus on a special type of metaphor—simile. A simile is a figure of speech that directly compares two things using connecting words such as like, as, than in English and “œ” or “πÇ” in Chinese. Due to the use of such comparators, it is much easier to locate similes compared with locating other types of metaphors. As a result, it is possible to collect and annotate large scale of simile sentences and investigate data-driven simile recognition. This task is to find simile sentences and extract simile components, i.e., the tenor and the vehicle. The mined simile structures can potentially be used to support general metaphor analysis, where large scale training data is lacking.\n\nHowever, simile recognition is still challenging due to the diversity of syntactic roles of a word and the distinction between metaphorical and literal comparisons. As shown in Table 1, a sentence containing a comparator may not trigger a simile. It is necessary to analyze the relationship between meanings of concepts. And It is also difficult to define a complete set of rules to extract the objects to be compared with high accuracy and coverage.\n\nThis paper presents an end-to-end neural network framework for simile sentence recognition. Specifically, we make the following contributions:\n\nWe build a dataset consisting of 11.3k sentences containing a frequently used comparator “œ” for simile recognition in Chinese, which can support data-driven approaches. In contrast to English, datasets on simile or metaphor analysis are relatively less in Chinese. This dataset provides a new resource for related research.\nWe propose a neural multitask learning framework jointly optimizing three tasks: simile sentence classification, simile component extraction and language modeling. Simile classification is to determine whether a sentence with a comparator contains a simile, without knowing exactly what the tenor and the vehicle are. Simile component extraction aims to locate the tenor and the vehicle in a simile sentence. Intuitively, the two tasks should benefit each other. We design our model to enhance interactions between the two tasks. We also borrow the idea of Rei (2017) by incorporating a language modeling task, which attempts to predict neighbor words. All three tasks consider the whole sentence so that rich context information is involved.\nWe conduct comprehensive experiments. The results demonstrate that the neural end-to-end framework is superior to feature-based and rule-based baselines and every single model can benefit from multitask learning. Simile sentence classification can be solved very well, while simile component extraction is more challenging. With multitask learning enhanced classifier and extractor, a classification-then-extraction method achieves the best performance for simile component extraction.",
       "charge": false,
       "remarks": "some chinese characters are not copied well"
     },
     {
       "title": "Neural Simile Recognition with Cyclic Multitask Learning and Local Attention",
       "author":["Jiali Zeng", "Linfeng Song", "Jinsong Su", "Jun Xie", "Wei Song", "Jiebo Luo"] ,
       "year": 2020,
       "abstract": "",
       "introduction": "",
       "charge": false
     },
     {
       "title": "Bridging Towers of Multi-task Learning with a Gating Mechanism for Aspect-based Sentiment Analysis and Sequential Metaphor Identification",
       "author":["Rui Mao", "Xiao Li"] ,
       "year": 2021,
       "abstract": "",
       "introduction": "",
       "charge": false
     },
     {
       "title": "Generating similes effortlessly like a Pro: A Style Transfer Approach for Simile Generation",
       "author":["Tuhin Chakrabarty", "Smaranda Muresan", "Nanyun Peng"] ,
       "year": 2020,
       "abstract": "Literary tropes, from poetry to stories, are at the crux of human imagination and communication. Figurative language such as a simile go beyond plain expressions to give readers new insights and inspirations. In this paper, we tackle the problem of simile generation. Generating a simile requires proper understanding for effective mapping of properties between two concepts. To this end, we first propose a method to automatically construct a parallel corpus by transforming a large number of similes collected from Reddit to their literal counterpart using structured common sense knowledge. We then propose to fine-tune a pre-trained sequence to sequence model, BART (Lewis et al 2019), on the literal-simile pairs to gain generalizability, so that we can generate novel similes given a literal sentence. Experiments show that our approach generates 88% novel similes that do not share properties with the training data. Human evaluation on an independent set of literal statements shows that our model generates similes better than two literary experts 37% of the time when compared pairwise. We also show how replacing literal sentences with similes from our best model in machine-generated stories improves evocativeness and leads to better acceptance by human judges.",
       "introduction": "Comparisons are inherent linguistic devices that express the likeness of two entities, concepts or ideas. When used in a figurative sense, these comparisons are called similes. They are a figure of speech that compare two different kinds of things, usually with the intent to make the description more emphatic or vivid, being often used in literature and poetry to spark the reader’s imagination (Paul et al., 1970). Take the following two examples: “The city was like a painting”, and “If it falls into the wrong hands, it would be as catastrophic as a nuclear bomb.” In the first example, the comparison draws on the implicit “beauty” property being shared by the two very different entities, city and painting, while in the second, the “catastrophic” property is shared by falling into the wrong hands and a nuclear bomb. While most computational work has focused on simile detection (Niculae and Danescu-Niculescu-Mizil, 2014; Mpouli, 2017; Qadir et al., 2015, 2016; Zeng et al., 2019; Liu et al., 2018), research on simile generation is under-explored. Generating similes could impact many downstream applications such as creative writing assistance, and literary or poetic content creation. To tackle the generation problem, we take advantage of the relatively simple structure of similes that consists of five elements (Hanks, 2013; Niculae and Danescu-Niculescu-Mizil, 2014): the TOPIC (usually a noun phrase that acts as the logical subject), the VEHICLE (the logical object of the comparison, usually a noun phrase), the PROPERTY (what the two things being compared have in common, usually an adjective), the EVENT (eventuality or state, usually a verb), and the COMPARATOR (the trigger word or phrase that marks the presence of a comparison, usually the preposition “like” or “as...as”). All elements of a simile are explicit, with the exception of PROPERTY, which can be both implicit and explicit. If we take the first example above, its structure is: “[The city/TOPIC] [was/EVENT] [like/COMPARATOR] [a painting/VEHICLE]” (PROPERTY is implicit). Unlike metaphors, the semantic context of similes tends to be very shallow, transferring a single property (Hanks, 2013). Moreover, the explicit syntactic structure of similes allows, in exchange, for more lexical creativity (Niculae and Danescu-Niculescu-Mizil, 2014). We focus on the task of generating a simile starting from a literal utterance that contains the TOPIC, EVENT, and PROPERTY. We frame this task as a style-transfer problem (Shen et al., 2017; Fu et al., 2017; Li et al., 2018; Sudhakar et al., 2019), where the author’s intent is to make the description of the TOPIC more emphatic by introducing a comparison with the VEHICLE via a shared PROPERTY (See Figure 1 for examples of literal descriptive sentences and the generated similes). We call our approach SCOPE (Style transfer through COmmonsense PropErty). There are two main challenges we need to address: 1) the lack of training data that consists of pairs of literal utterances and their equivalent simile to train a supervised model; 2) ensuring that the generated simile makes a meaningful comparison between the TOPIC and the VEHICLE via the shared PROPERTY explicitly or implicitly expressed (e.g., Figure 1 GenSimile1 and GenSimile2, respectively). To the best of our knowledge, this is the first work attempting to generate similes. By framing the task as a style-transfer problem we make three contributions: Automatic creation of a parallel corpus of [literal sentence, simile] pairs. Our constructed corpus contains 87,843 such pairs. As a first step, we use distant supervision to automatically collect a set of self-labeled similes using the phrase like a. We then convert these similes to their literal versions by removing the COMPARATOR and replacing the VEHICLE with the associated PROPERTY by leveraging the structured common sense knowledge achieved from COMET (Bosselut et al., 2019), a language model fine-tuned on ConceptNet (Speer et al., 2017). For example, for the simile “Love is like a unicorn” our method will generate “Love is rare” (Section 2.1). Transfer learning from a pre-trained model for generating high-quality similes. Our system SCOPE, fine-tunes BART (Lewis et al., 2019) — a state-of-the-art pre-trained denoising autoencoder built with a sequence to sequence model, on our automatically collected parallel corpus of [literal sentence, simile] pairs (Section 2.2) to generate similes. Human evaluations show that this approach generates similes that are better 37% of the time on average compared to 2 literary experts, 82% and 63% of times compared to two well-crafted baselines, and 68% of the times compared to a state-of-the-art system for metaphor generation (Stowe et al., 2020) (Section 4). A task-based evaluation. We show the effectiveness of the generated similes as a tool for enhancing creativity and evocativeness in machine-generated stories. Evaluation via Amazon Mechanical Turk shows that stories containing similes generated by SCOPE are preferred by Turkers 42% of the time compared to stories without similes, which are preferred 25% of the time (Section 6).",
       "charge": false
     },
     {
       "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction",
       "author":["Antoine Bosselut", "Hannah Rashkin", "Maarten Sap", "Chaitanya Malaviya", "Asli Celikyilmaz", "Yejin Choi"] ,
       "year": 2019,
       "abstract": "We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.",
       "introduction": "When reading text, humans make commonsense inferences that frame their understanding of the narrative being presented. For machines to achieve this capability, they must be able to acquire relevant and correct commonsense for an unbounded set of situations. In this work, we cast commonsense acquisition as knowledge base construction and investigate whether large-scale language models can effectively learn to generate the knowledge necessary to automatically construct a commonsense knowledge base (KB).\n\nAutomatic KB construction is a long-standing goal of artificial intelligence research due to the difficulty of achieving high concept coverage in high-precision curated KBs (Lenat, 1995; Miller, 1995). Previous work has developed models capable of reading and extracting semi-structured text (Suchanek et al., 2007; Hoffart et al., 2013; Auer et al., 2007; Bollacker et al., 2008) and unstructured text (Dong et al., 2014; Carlson et al., 2010; Nakashole et al., 2011, 2012; Niu, 2012) into relational schemas that can be queried for downstream applications. A common thread of these approaches, however, is the focus on encyclopedic knowledge, which lends itself to a well-defined space of entities and relations that can be modeled.\n\nCommonsense knowledge, however, does not cleanly fit into a schema comparing two entities with a known relation, leading current approaches to model \"entities\" as natural language phrases and relations as any concept that can link them (Li et al., 2016; Sap et al., 2019). OpenIE approaches display this property of open text entities and relations (Etzioni et al., 2011; Fader et al., 2011; Mausam et al., 2012), but being extractive, they only capture knowledge that is explicitly mentioned in text, limiting their applicability for capturing commonsense knowledge, which is often implicit (Gordon and Van Durme, 2013).\n\nMeanwhile, recent progress in training deep contextualized language models (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2018) provides an opportunity to explore beyond extractive methods as an avenue for commonsense KB construction. These large-scale language models display impressive performance when their underlying representations are tuned to solve end tasks, achieving state-of-the-art results on a variety of complex problems. In this work, we define the COMmonsEnse Transformer (COMET), which constructs commonsense KBs by using existing tuples as a seed set of knowledge on which to train. Using this seed set, a pre-trained language model learns to adapt its learned representations to knowledge generation and produces novel tuples that are high quality.\n\nWe summarize our contributions in this work as follows. First, we develop a generative approach to knowledge base construction. A model must learn to produce new nodes and identify edges between existing nodes by generating phrases that coherently complete an existing seed phrase and relation type. Second, we develop a framework for using large-scale transformer language models to learn to produce commonsense knowledge tuples. Finally, we perform an empirical study on the quality, novelty, and diversity of the commonsense knowledge produced by our approach for two domains, ATOMIC and ConceptNet, as well as an efficiency study on the number of seed tuples needed to learn an effective knowledge model. The results indicate that COMET is able to produce high-quality tuples, as human judges find that 77.5% of generated tuples for ATOMIC events and 91.7% of generated tuples for ConceptNet relations are correct.",
       "charge": false
     },
     {
       "title": "Writing Polishment with Simile: Task, Dataset and A Neural Approach",
       "author":["Jiayi Zhang", "Zhi Cui", "Xiaoqiang Xia", "Yalong Guo", "Yanran Li", "Chen Wei", "Jianwei Cui"] ,
       "year": 2021,
       "abstract": "",
       "introduction": "",
       "charge": false
     },
     {
       "title": "Rhetorically Controlled Encoder-Decoder for Modern Chinese Poetry Generation",
       "author":["Zhiqiang Liu", "Zuohui Fu", "Jie Cao", "Gerard de Melo", "Yik-Cheung Tam", "Cheng Niu", "Jie Zhou"] ,
       "year": 2019,
       "abstract": "Rhetoric is a vital element in modern poetry, and plays an essential role in improving its aesthetics. However, to date, it has not been considered in research on automatic poetry generation. In this paper, we propose a rhetorically controlled encoder-decoder for modern Chinese poetry generation. Our model relies on a continuous latent variable as a rhetoric controller to capture various rhetorical patterns in an encoder, and then incorporates rhetoric-based mixtures while generating modern Chinese poetry. For metaphor and personification, an automated evaluation shows that our model outperforms state-of-the-art baselines by a substantial margin, while human evaluation shows that our model generates better poems than baseline methods in terms of fluency, coherence, meaningfulness, and rhetorical aesthetics.",
       "introduction": "Modern Chinese poetry, originating from 1900 CE, is one of the most important literary formats in Chinese culture and indeed has had a profound influence on the development of modern Chinese culture. Rhetoric is a vital element in modern poetry, and plays an important role in enhancing its aesthetics. Incorporating intentional rhetorical embellishments is essential to achieving the desired stylistic aspects of impassioned modern Chinese poetry. In particular, the use of metaphor and personification, both frequently used forms of rhetoric, are able to enrich the emotional impact of a poem. Specifically, a metaphor is a figure of speech that describes one concept in terms of another one. Within this paper, the term “metaphor” is considered in the sense of a general figure of speech 比喻 (bi yu), encompassing both metaphor in its narrower sense and similes. Personification is a figure of speech in which a thing, an idea or an animal is given human attributes, i.e., nonhuman objects are portrayed in such a way that we feel they have the ability to act like human beings. For example, 她笑起来像花儿一样 (’She smiles like lovely flowers’) with its connection between smiling and flowers highlights extraordinary beauty and pureness in describing the verb ’smile’. 夜空中的星星眨着眼睛 (’Stars in the night sky squinting’) serves as an example of personification, as stars are personified and described as squinting, which is normally considered an act of humans, but here is invoked to more vividly describe twinkling stars.\n\nAs is well known, rhetoric encompasses a variety of forms, including metaphor, personification, exaggeration, and parallelism. For our work, we collected more than 8,000 Chinese poems and over 50,000 Chinese song lyrics. Based on the statistics given in Table 1, we observe that metaphor and personification are the most frequently used rhetorical styles in modern Chinese poetry and lyrics (see Section 4.1 for details about this data). Hence, we will mainly focus on the generation of metaphor and personification in this work. As an example, an excerpt from the modern Chinese poem 独自 (Alone) is given in Figure 1, where the fourth sentence (highlighted in blue) invokes a metaphorical simile, while the second one (highlighted in red) contains a personification.\n\nIn recent years, neural generation models have become widespread in natural language processing (NLP), e.g., for response generation in dialogue (Le et al., 2018), answer or question generation in question answering, and headline generation in news systems. At the same time, poetry generation is of growing interest and has attained high levels of quality for classical Chinese poetry. Previously, Chinese poem composing research mainly focused on traditional Chinese poems. In light of the mostly short sentences and the metrical constraints of traditional Chinese poems, the majority of research attention focused on term selection to improve the thematic consistency (Wang et al., 2016).\n\nIn contrast, modern Chinese poetry is more flexible and rich in rhetoric. Unlike sentiment-controlled or topic-based text generation methods (Ghazvininejad et al., 2016), which have been widely used in poetry generation, existing research has largely disregarded the importance of rhetoric in poetry generation. Yet, to emulate human-written modern Chinese poems, it appears necessary to consider not only the topics but also the form of expression, especially with regard to rhetoric. In this paper, we propose a novel rhetorically controlled encoder-decoder framework inspired by the above sentiment-controlled and topic-based text generation methods, which can effectively generate poetry with metaphor and personification.\n\nOverall, the contributions of the paper are as follows:\n• We present the first work to generate modern Chinese poetry while controlling for the use of metaphor and personification, which play an essential role in enhancing the aesthetics of poetry.\n• We propose a novel metaphor and personification generation model with a rhetorically controlled encoder-decoder.\n• We conduct extensive experiments showing that our model outperforms the state-of-the-art both in automated and human evaluations.",
       "charge": false
     },
     {
       "title": "Nominal Metaphor Generation with Multitask Learning",
       "author":["Yucheng Li", "Chenghua Lin", "Frank Geurin"],
       "year": 2022,
       "abstract": "Metaphor generation is a challenging task which can impact many downstream tasks such as improving user satisfaction with dialogue systems and story generation. This paper tackles the problem of Chinese nominal metaphor generation by introducing a multitask metaphor generation framework with self-training and metaphor identification mechanisms. Self-training addresses the data scarcity issue of metaphor datasets. That is, instead of solely relying on labelled metaphor datasets which are usually small in size, self-training helps identify potential metaphors from a large-scale unlabelled corpus for metaphor generation. The metaphor weighting mechanism enables our model to focus on the metaphor-related parts of the input (e.g., the comparison of the metaphor and comparator) during model learning and thus improves the metaphoricity of the generated metaphors. Our model is trained on an annotated corpus consisting of 6.3k sentences that contain diverse metaphorical expressions. Experimental results show that our model is able to generate metaphors with better readability and creativity compared to the baseline models, even in the situation where training data is insufficient.",
       "introduction": "Metaphor is commonly used in human language as an effective communication device. Typically, metaphors compare a concept or an object to another with the intent to make the expression more vivid, or to make unfamiliar things easier to understand (Paul, 1970).\n\nAccording to linguistic studies of Chinese, metaphors are particularly important in Chinese as metaphor is the dominant figurative language in Chinese (Wang, 2004). As shown in Table 1, there are different types of Chinese metaphors. Nominal Metaphors (NMs), also known as 比喻 in Chinese, are figures of speech associating a noun with another noun through a comparator such as and 像,是,变成 (equivalent to like, be, become in English). Wang (2004) claims that the nominal metaphor requires the comparison to be drawn from objects different in nature. Therefore, even though the fourth example in the table uses a classic comparator “like”, it does not make it a metaphor as it compares a person to another person. Verb metaphors are metaphors whose verbs are used metaphorically. The verb metaphor shown in Table 1 uses weaving, a verb which is usually related to cloth or loom, to describe human relationships. The third type of Chinese metaphor is personification (also known as 拟人 in Chinese), which treats objects as human and can act like humans.\n\nPrevious efforts on metaphor generation demonstrate the task can bring benefits to a wide range of NLG downstream tasks. Glucksberg (1989) suggested that verb metaphors are important to an engaging conversation. Zhou (2020) showed machine-generated NMs are effective in stimulating user interest in communicating with chatbots. Chakrabarty et al. (2020, 2021) conducted human evaluations comparing literal expressions from machine-generated stories and poems with machine-generated metaphors and found users prefer the text with metaphors.\n\nIn this paper, we mainly focus on generating the nominal metaphors. The generation of the NMs is defined as follows: given the subject of the metaphor, i.e., “Lilies” in the first example of Table 1, generate a comparison containing the comparator and the object of the comparison, i.e., “like” and “a bottle of perfume” in the example, respectively. There are two main challenges to the Chinese metaphor generation task. The first issue is the annotated corpus. Existing Chinese metaphor corpora are not large enough to power current data-driven text generation approaches. Second, the auto-regressive fashion language modelling is ineffective for learning metaphor generation. Because a metaphor can be hidden in a very long sentence, the generative model tends to learn the entire sentence sequence rather than focusing on the metaphorical part of the input.\n\nTo address the aforementioned challenges, we propose a novel neural metaphor generation model that requires only limited labelled metaphor data for model training. This is achieved by a multitask framework which jointly performs novel self-training and metaphor weighting mechanisms. First, to tackle the scarcity issue of metaphor datasets, we employ self-training to leverage additional unlabelled data to improve the metaphor generation performance. Self-training consists of three main steps: (1) train a teacher model on labelled training data; (2) detect potential metaphors in the unlabelled corpus; and (3) train a student model on the combination of the labelled as well as newly identified metaphors from the unlabelled data. Second, we propose to employ metaphor identification to reveal metaphor-related parts of the input. This permits our model to focus on the metaphor-related parts of the entire input sentence via assigning higher weights to metaphor-related content. Introducing metaphor identification not only improves the efficiency of the model training process but also improves the metaphoricity of the generated metaphors.\n\nAs there are limited data available for nominal metaphor generation, we collect and annotate two corpora for our model training, namely, Chinese Metaphor Corpus (CMC) and Chinese Literature Corpus (CLC). CMC contains 2.7k metaphor examples and 3.5k literal examples, which can be used for both metaphor detection and generation. CLC is a large-scale unlabelled Chinese literature corpus, which can be leveraged by our self-training algorithm for identifying additional high-quality labelled metaphors. We conduct both automatic and human evaluation to evaluate our model’s performance in metaphor generation. Experimental results show that our model is able to generate metaphors with better readability and creativity compared to the baseline models, even in the situation where training data is insufficient. Source code and data can be found at https://github.com/liyucheng09/Metaphor_Generator.",
       "charge": false
     },
     {
       "title": "Probing Simile Knowledge from Pre-trained Language Models",
       "author":["Weijie Chen", "Yongzhu Chang", "Rongsheng Zhang", "Jiashu Pu", "Guandan Chen", "Le Zhang", "Yadong Xi", "Yijiang Chen", "Chang Su"] ,
       "year": 2022,
       "abstract": "Simile interpretation (SI) and simile generation (SG) are challenging tasks for NLP because models require adequate world knowledge to produce predictions. Previous works have employed many hand-crafted resources to bring knowledge-related into models, which is time-consuming and labor-intensive. In recent years, pre-trained language models (PLMs) based approaches have become the de-facto standard in NLP since they learn generic knowledge from a large corpus. The knowledge embedded in PLMs may be useful for SI and SG tasks. Nevertheless, there are few works to explore it. In this paper, we probe simile knowledge from PLMs to solve the SI and SG tasks in the unified framework of simile triple completion for the first time. The backbone of our framework is to construct masked sentences with manual patterns and then predict the candidate words in the masked position. In this framework, we adopt a secondary training process (Adjective-Noun mask Training) with the masked language model (MLM) loss to enhance the prediction diversity of candidate words in the masked position. Moreover, pattern ensemble (PE) and pattern search (PS) are applied to improve the quality of predicted words. Finally, automatic and human evaluations demonstrate the effectiveness of our framework in both SI and SG tasks.",
       "introduction": "The simile, which is a special type of metaphor, is defined as a figurative expression in which two fundamentally different things are explicitly compared, usually using “like” or “as” (Israel et al., 2004; Zeng et al., 2020). It is widely used in literature because it can inspire the reader’s imagination (Paul, 1970) by giving a vivid and unexpected analogy between two objects with similar attributes. A simile sentence usually contains three key elements: the tenor, the attribute and the vehicle, which can be defined in the form of a triple (tenor, attribute, vehicle) (Song et al., 2021). For example, the simile sentence “Love is as thorny as a rose” can be extracted as the triple (love, thorny, rose), where the tenor is “love”, the vehicle is “rose”, and the attribute is “thorny”. Note that a simile triple can produce different simile sentences with different templates. For the example triple above, the simile sentences can be also constructed as “love is thorny like a rose\" with the pattern “tenor is attribute like vehicle\".\n\nThe study of simile is beneficial to many downstream tasks, like sentiment analysis (Rentoumi et al., 2012), question answering (Zheng et al., 2020), writing polishment (Zhang et al., 2021), and creative writing (Gero and Chilton, 2019). Simile Interpretation (SI) (Qadir et al., 2016; Su et al., 2016) and simile generation (SG) (Yu and Wan, 2019) are the two important tasks in the study of simile (Tong et al., 2021). The SI task is to find suitable attributes as a mediator between the tenor and vehicle. Likewise, the SG task is to select a proper vehicle for the tenor with the given attribution. And these two tasks can be unified into the form of simile triple completion (STC) (Song et al., 2021) as shown in Figure 1.\n\nPrevious works on the SI and SG tasks relied on a limited training corpus or labor-intensive knowledge base, which leads to an upper limit on the diversity of results. (Song et al., 2021) collected sentences containing comparator words from a Chinese essays corpus and manually annotated them to obtain the simile triple. Some works (Stowe et al., 2021; Gero and Chilton, 2019; Veale et al., 2016) relied on a knowledge base such as ConceptNet2, FrameNet3, which are scarce to other languages because it is time-consuming and labor-intensive to construct such a knowledge base. It is notable that pre-trained language models (PLMs) (Devlin et al., 2019; Radford et al., 2019) have made significant progress recently in many NLP tasks since it learns generic knowledge such as grammar, common sense from a large corpus (Davison et al., 2019; Liu et al., 2021a, b). Considering the sufficient existence of simile in the large corpus, it’s reasonable to assume that PLMs are equipped with rich knowledge of similes during the pre-training stage. However, few works have explored directly probing the knowledge of simile from the PLMs.\n\nIn this paper, we propose a unified framework to solve the SI and SG tasks by mining the knowledge in PLMs, which does not require fine-labeled training data or knowledge graphs. The backbone of our method is to construct masked sentences with manual patterns from an incomplete simile triple, and then use language models with MLM heads to predict the masked words over the task-specific vocabulary. We take the K words with the highest probability as the result words. However, there are problems with this crude approach. Firstly, the predicted words should be creative and surprised for the simile sentence. On the contrary, the PLMs tend to predict common words (e.g., good, bad) with a higher probability. To address this issue, we introduce a secondary pre-training stage - AdjectiveNoun mask Training (ANT), where only the noun or adjective contained in the amod dependencies (Nivre et al., 2017) could be masked in the MLM training process and the number of words masked times are limited. Secondly, the words predicted by MLM have a preference for different patterns. For this reason, we employ a pattern ensemble to obtain high-quality and robust results. Finally, we also introduce a prompt-search method to improve the quality of the simile component predictions.\n\nOur main contributions are as follows:\n\nWe propose a unified framework to solve both the simile interpretation (SI) and simile generation (SG) tasks based on pre-trained models. To the best of our knowledge, it is the first work to introduce pre-trained language models to unify these tasks.\nWe propose a secondary pre-training stage that effectively improves the prediction diversity. Further, we employ the pattern-ensemble and pattern-search approaches to obtain better results.\nWe compare our models on both automated metrics and manual measures, and the results show that our approach outperforms the baselines in terms of diversity and correctness.",
       "charge": false
     }
  ]
}